---
layout: post
title: The best book on Neural Network and Deep Learning under Creative commons for
  those with foundation in Prob, Stat, Calculus, LinAl, & OT. .
date: '2020-08-06T17:55:00+00:00'
tags: AI ML
---

Applying algorithm on MNIST data set where it all started: 
Michael A. Nielsen, Neural Networks and Deep Learning, Determination Press, 2015 - Sigmoid, Backpropogation applied on SGD, Overfitting/Bias/L1-L2 regularization/Dropouts on Momentum Gradient Descent with TANH/RELU activations

The book has simple and beautiful illustrations of extending simple shallow ANN to Deep neural nets without using higher mathematics. The challenges in training deep nets by explaining vanishing and exploding gradient problem, but does not cover how to handle them with Golrot/Benigo normalized functions and null bias initialization.

The final chapter introduces CNN and the drivers: Local receptive fields, feature maps, strides, shared weights/kernel,  shared biases/filters. This quickly gets complicated to comprehend, but develops intuition on how image recognition algorithms work by drastically reducing the hyperparameters. 

This leads you to wonder why so much is made out of AI explain-ability while human explain-ability data is equally difficult for squiggly character.
http://neuralnetworksanddeeplearning.com/
